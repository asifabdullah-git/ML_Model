{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      location    mean_X    mean_Y    mean_Z     std_X     std_Y     std_Z  \\\n",
      "2586         2 -0.166218  0.741565 -0.274216  0.367640  0.331478  0.432264   \n",
      "1752         1 -0.031501  0.110551 -0.984593  0.063066  0.080513  0.069576   \n",
      "3349         3  0.018262  0.513564 -0.854313  0.015786  0.055122  0.044759   \n",
      "2187         2  0.640187  0.717811  0.170213  0.083785  0.120145  0.173563   \n",
      "751          1  0.345142  0.737243 -0.434588  0.047831  0.327853  0.252273   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "828          1  0.295562  0.557944 -0.602977  0.072749  0.385935  0.268054   \n",
      "3299         3 -0.059503  0.658273 -0.750939  0.054313  0.081193  0.090754   \n",
      "138          1  0.131733  0.451024 -0.888145  0.022883  0.040484  0.016916   \n",
      "3020         3 -0.941485  0.184507 -0.328145  0.455337  0.385626  0.271059   \n",
      "1724         1 -0.017724  0.156339 -1.006215  0.075337  0.069647  0.075446   \n",
      "\n",
      "        skew_X    skew_Y    skew_Z  label  \n",
      "2586 -0.317013 -0.825197  0.475958     22  \n",
      "1752 -2.651486 -0.189325  0.969762     15  \n",
      "3349 -0.097865 -0.389900  0.424951     33  \n",
      "2187 -0.361379  0.701463 -0.848525     21  \n",
      "751   1.024308 -1.669549 -1.370273     12  \n",
      "...        ...       ...       ...    ...  \n",
      "828  -0.605226 -1.207259  0.499851     12  \n",
      "3299 -0.347060  0.261379  0.111002     33  \n",
      "138  -0.219537  0.164857  0.185980     11  \n",
      "3020  0.761957  0.507555 -0.482209     31  \n",
      "1724  0.167856  0.575590  0.218851     15  \n",
      "\n",
      "[3392 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('final_filter.csv')\n",
    "#data\n",
    "data = data.iloc[mp.random.permutation(len(data))]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.00000000e+00, -1.66217957e-01,  7.41565399e-01, ...,\n",
       "        -8.25197156e-01,  4.75957645e-01,  2.20000000e+01],\n",
       "       [ 1.00000000e+00, -3.15008550e-02,  1.10550537e-01, ...,\n",
       "        -1.89325302e-01,  9.69762426e-01,  1.50000000e+01],\n",
       "       [ 3.00000000e+00,  1.82622600e-02,  5.13564220e-01, ...,\n",
       "        -3.89900259e-01,  4.24950926e-01,  3.30000000e+01],\n",
       "       ...,\n",
       "       [ 1.00000000e+00,  1.31732750e-01,  4.51023880e-01, ...,\n",
       "         1.64856726e-01,  1.85979626e-01,  1.10000000e+01],\n",
       "       [ 3.00000000e+00, -9.41485110e-01,  1.84506860e-01, ...,\n",
       "         5.07555463e-01, -4.82209391e-01,  3.10000000e+01],\n",
       "       [ 1.00000000e+00, -1.77239990e-02,  1.56338806e-01, ...,\n",
       "         5.75589974e-01,  2.18851454e-01,  1.50000000e+01]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = data.values\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,0:7]\n",
    "Y = dataset[:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2374, 7) (509, 7) (509, 7) (2374,) (509,) (509,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([    Dense(32, activation='relu', input_shape=(7,)),    \n",
    "                    Dense(8, activation='relu'),    \n",
    "                    Dense(1, activation='sigmoid'),])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size = 128\n",
    "#nb_classes = 10\n",
    "#nb_epochs = 2\n",
    "\n",
    "#(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "#X_train = X_train.reshape(60000, 784)\n",
    "#X_test = X_test.reshape(10000, 784)\n",
    "#X_train = X_train.astype(\"float32\")\n",
    "#X_test = X_test.astype(\"float32\")\n",
    "#X_train /= 255\n",
    "#X_test /= 255\n",
    "\n",
    "#print(X_train.shape[0], \"train samples\")\n",
    "#print(X_test.shape[0], \"test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "#y_test =  np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "#model = Sequential()\n",
    "\n",
    "#model.add(Dense(output_dim = 100, input_dim = 784, activation= \"relu\"))\n",
    "#model.add(Dense(output_dim = 200, activation = \"relu\"))\n",
    "#model.add(Dense(output_dim = 200, activation = \"relu\"))\n",
    "#model.add(Dense(output_dim = nb_classes, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\",  metrics=\"accuracy\")\n",
    "\n",
    "#model.fit(X_train, y_train, batch_size = batch_size, nb_epoch = nb_epochs,  verbose = 2, validation_data = (X_test, y_test))\n",
    "#score = model.evaluate(X_test, y_test, verbose = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2374 samples, validate on 509 samples\n",
      "Epoch 1/100\n",
      "2374/2374 [==============================] - 2s 1ms/step - loss: 0.5262 - accuracy: 0.0000e+00 - val_loss: 0.4239 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "2374/2374 [==============================] - 0s 134us/step - loss: 0.3276 - accuracy: 0.0000e+00 - val_loss: 0.3184 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "2374/2374 [==============================] - 0s 103us/step - loss: 0.2381 - accuracy: 0.0000e+00 - val_loss: 0.2790 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "2374/2374 [==============================] - 0s 118us/step - loss: 0.1966 - accuracy: 0.0000e+00 - val_loss: 0.2679 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "2374/2374 [==============================] - 0s 150us/step - loss: 0.1769 - accuracy: 0.0000e+00 - val_loss: 0.2637 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "2374/2374 [==============================] - 0s 151us/step - loss: 0.1585 - accuracy: 0.0000e+00 - val_loss: 0.2536 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "2374/2374 [==============================] - 0s 111us/step - loss: 0.1374 - accuracy: 0.0000e+00 - val_loss: 0.2431 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "2374/2374 [==============================] - 0s 150us/step - loss: 0.1043 - accuracy: 0.0000e+00 - val_loss: 0.2177 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "2374/2374 [==============================] - 1s 220us/step - loss: 0.0583 - accuracy: 0.0000e+00 - val_loss: 0.1903 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "2374/2374 [==============================] - 0s 181us/step - loss: -0.0149 - accuracy: 0.0000e+00 - val_loss: 0.1504 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "2374/2374 [==============================] - 0s 191us/step - loss: -0.1349 - accuracy: 0.0000e+00 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "2374/2374 [==============================] - 0s 97us/step - loss: -0.3758 - accuracy: 0.0000e+00 - val_loss: -0.0599 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "2374/2374 [==============================] - 0s 105us/step - loss: -0.9069 - accuracy: 0.0000e+00 - val_loss: -0.4958 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "2374/2374 [==============================] - 0s 132us/step - loss: -2.4351 - accuracy: 0.0000e+00 - val_loss: -1.7028 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "2374/2374 [==============================] - 0s 108us/step - loss: -7.4150 - accuracy: 0.0000e+00 - val_loss: -5.2269 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "2374/2374 [==============================] - 0s 91us/step - loss: -63.7712 - accuracy: 0.0000e+00 - val_loss: -78.0656 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "2374/2374 [==============================] - 0s 104us/step - loss: -295.5957 - accuracy: 0.0000e+00 - val_loss: -2105.1228 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "2374/2374 [==============================] - 0s 113us/step - loss: 37.8669 - accuracy: 0.0000e+00 - val_loss: 54.4941 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "2374/2374 [==============================] - 0s 98us/step - loss: 0.4358 - accuracy: 0.0000e+00 - val_loss: 47.1515 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "2374/2374 [==============================] - 0s 115us/step - loss: -0.6612 - accuracy: 0.0000e+00 - val_loss: 51.3706 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "2374/2374 [==============================] - 0s 179us/step - loss: 7045.1354 - accuracy: 0.0000e+00 - val_loss: 0.2985 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "2374/2374 [==============================] - 0s 144us/step - loss: 0.2369 - accuracy: 0.0000e+00 - val_loss: 0.2937 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "2374/2374 [==============================] - 0s 98us/step - loss: 0.2296 - accuracy: 0.0000e+00 - val_loss: 0.2916 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "2374/2374 [==============================] - 0s 102us/step - loss: 0.2253 - accuracy: 0.0000e+00 - val_loss: 0.2909 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "2374/2374 [==============================] - 0s 109us/step - loss: 0.2226 - accuracy: 0.0000e+00 - val_loss: 0.2907 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "2374/2374 [==============================] - 0s 120us/step - loss: 0.2202 - accuracy: 0.0000e+00 - val_loss: 0.2910 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "2374/2374 [==============================] - 0s 123us/step - loss: 0.2186 - accuracy: 0.0000e+00 - val_loss: 0.2915 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "2374/2374 [==============================] - 0s 144us/step - loss: 0.2180 - accuracy: 0.0000e+00 - val_loss: 0.2920 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "2374/2374 [==============================] - 0s 142us/step - loss: 0.2173 - accuracy: 0.0000e+00 - val_loss: 0.2926 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "2374/2374 [==============================] - 0s 127us/step - loss: 0.2168 - accuracy: 0.0000e+00 - val_loss: 0.2930 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "2374/2374 [==============================] - 0s 107us/step - loss: 0.2166 - accuracy: 0.0000e+00 - val_loss: 0.2936 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "2374/2374 [==============================] - 0s 143us/step - loss: 0.2163 - accuracy: 0.0000e+00 - val_loss: 0.2940 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "2374/2374 [==============================] - 0s 92us/step - loss: 0.2162 - accuracy: 0.0000e+00 - val_loss: 0.2946 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "2374/2374 [==============================] - 0s 96us/step - loss: 0.2159 - accuracy: 0.0000e+00 - val_loss: 0.2951 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "2374/2374 [==============================] - 0s 120us/step - loss: 0.2159 - accuracy: 0.0000e+00 - val_loss: 0.2957 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "2374/2374 [==============================] - 0s 90us/step - loss: 0.2160 - accuracy: 0.0000e+00 - val_loss: 0.2958 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "2374/2374 [==============================] - 0s 93us/step - loss: 0.2157 - accuracy: 0.0000e+00 - val_loss: 0.2962 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "2374/2374 [==============================] - 0s 103us/step - loss: 0.2157 - accuracy: 0.0000e+00 - val_loss: 0.2965 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "2374/2374 [==============================] - 0s 130us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2964 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "2374/2374 [==============================] - 0s 113us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2965 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "2374/2374 [==============================] - 0s 103us/step - loss: 0.2157 - accuracy: 0.0000e+00 - val_loss: 0.2967 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "2374/2374 [==============================] - 0s 100us/step - loss: 0.2157 - accuracy: 0.0000e+00 - val_loss: 0.2969 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "2374/2374 [==============================] - 0s 133us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2971 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "2374/2374 [==============================] - ETA: 0s - loss: 0.2248 - accuracy: 0.0000e+ - 0s 98us/step - loss: 0.2157 - accuracy: 0.0000e+00 - val_loss: 0.2973 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "2374/2374 [==============================] - 0s 113us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2973 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "2374/2374 [==============================] - 0s 103us/step - loss: 0.2155 - accuracy: 0.0000e+00 - val_loss: 0.2974 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "2374/2374 [==============================] - 0s 134us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2975 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "2374/2374 [==============================] - 0s 92us/step - loss: 0.2157 - accuracy: 0.0000e+00 - val_loss: 0.2975 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "2374/2374 [==============================] - 0s 110us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2974 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "2374/2374 [==============================] - 0s 104us/step - loss: 0.2157 - accuracy: 0.0000e+00 - val_loss: 0.2976 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "2374/2374 [==============================] - 0s 129us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2977 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "2374/2374 [==============================] - 0s 98us/step - loss: 0.2158 - accuracy: 0.0000e+00 - val_loss: 0.2977 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "2374/2374 [==============================] - 0s 100us/step - loss: 0.2157 - accuracy: 0.0000e+00 - val_loss: 0.2978 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "2374/2374 [==============================] - 0s 101us/step - loss: 0.2155 - accuracy: 0.0000e+00 - val_loss: 0.2979 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "2374/2374 [==============================] - 0s 101us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2979 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "2374/2374 [==============================] - 0s 126us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2983 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "2374/2374 [==============================] - 0s 100us/step - loss: 0.2155 - accuracy: 0.0000e+00 - val_loss: 0.2983 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "2374/2374 [==============================] - 0s 106us/step - loss: 0.2157 - accuracy: 0.0000e+00 - val_loss: 0.2982 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "2374/2374 [==============================] - 0s 112us/step - loss: 0.2157 - accuracy: 0.0000e+00 - val_loss: 0.2984 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "2374/2374 [==============================] - 0s 126us/step - loss: 0.2157 - accuracy: 0.0000e+00 - val_loss: 0.2980 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "2374/2374 [==============================] - 0s 99us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2980 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "2374/2374 [==============================] - 0s 118us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2980 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "2374/2374 [==============================] - 0s 109us/step - loss: 0.2155 - accuracy: 0.0000e+00 - val_loss: 0.2980 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "2374/2374 [==============================] - 0s 101us/step - loss: 0.2155 - accuracy: 0.0000e+00 - val_loss: 0.2980 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "2374/2374 [==============================] - 0s 118us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2977 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "2374/2374 [==============================] - 0s 125us/step - loss: 0.2155 - accuracy: 0.0000e+00 - val_loss: 0.2980 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "2374/2374 [==============================] - 0s 88us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2979 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "2374/2374 [==============================] - 0s 94us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2977 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "2374/2374 [==============================] - 0s 98us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2977 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "2374/2374 [==============================] - 0s 101us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2977 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "2374/2374 [==============================] - 0s 99us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2976 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "2374/2374 [==============================] - 0s 111us/step - loss: 0.2158 - accuracy: 0.0000e+00 - val_loss: 0.2975 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "2374/2374 [==============================] - 0s 104us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2979 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "2374/2374 [==============================] - 0s 105us/step - loss: 0.2155 - accuracy: 0.0000e+00 - val_loss: 0.2983 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "2374/2374 [==============================] - 0s 97us/step - loss: 0.2155 - accuracy: 0.0000e+00 - val_loss: 0.2982 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "2374/2374 [==============================] - ETA: 0s - loss: 0.2248 - accuracy: 0.0000e+ - 0s 100us/step - loss: 0.2155 - accuracy: 0.0000e+00 - val_loss: 0.2983 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "2374/2374 [==============================] - 0s 98us/step - loss: 0.2157 - accuracy: 0.0000e+00 - val_loss: 0.2981 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "2374/2374 [==============================] - 0s 98us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2981 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "2374/2374 [==============================] - 0s 96us/step - loss: 0.2157 - accuracy: 0.0000e+00 - val_loss: 0.2982 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "2374/2374 [==============================] - 0s 95us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2981 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "2374/2374 [==============================] - 0s 99us/step - loss: 0.2155 - accuracy: 0.0000e+00 - val_loss: 0.2980 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "2374/2374 [==============================] - 0s 104us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2982 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "2374/2374 [==============================] - 0s 104us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2983 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "2374/2374 [==============================] - 0s 99us/step - loss: 0.2155 - accuracy: 0.0000e+00 - val_loss: 0.2983 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "2374/2374 [==============================] - 0s 100us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2984 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "2374/2374 [==============================] - 0s 104us/step - loss: 0.2155 - accuracy: 0.0000e+00 - val_loss: 0.2986 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "2374/2374 [==============================] - 0s 113us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2984 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "2374/2374 [==============================] - 0s 109us/step - loss: 0.2157 - accuracy: 0.0000e+00 - val_loss: 0.2984 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "2374/2374 [==============================] - 0s 111us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2983 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "2374/2374 [==============================] - 0s 105us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2984 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "2374/2374 [==============================] - 0s 100us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2983 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "2374/2374 [==============================] - 0s 100us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2984 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "2374/2374 [==============================] - 0s 98us/step - loss: 0.2157 - accuracy: 0.0000e+00 - val_loss: 0.2984 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "2374/2374 [==============================] - 0s 104us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2984 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "2374/2374 [==============================] - 0s 122us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2983 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "2374/2374 [==============================] - 0s 122us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2981 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "2374/2374 [==============================] - 0s 117us/step - loss: 0.2155 - accuracy: 0.0000e+00 - val_loss: 0.2981 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "2374/2374 [==============================] - 0s 141us/step - loss: 0.2156 - accuracy: 0.0000e+00 - val_loss: 0.2981 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "2374/2374 [==============================] - 0s 129us/step - loss: 0.2155 - accuracy: 0.0000e+00 - val_loss: 0.2983 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "2374/2374 [==============================] - 0s 142us/step - loss: 0.2157 - accuracy: 0.0000e+00 - val_loss: 0.2981 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, Y_train, \n",
    "                batch_size=10, epochs=100,\n",
    "                    validation_data=(X_val, Y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509/509 [==============================] - 0s 587us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
